{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Customer Churn Prediction Model </h1>\n",
    "<h4>By: Ravikumar Patel </h4></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer churn means the percentage of customers who stopped using the company's services or products during a certain period. This period could be days, months, quarters or years. So, if the company decides to use a month as a period, then they can deduct the value of customers remained after a month from the customers the company had at the beginning of the month and calculate the percentage of it. **Note**: It is important to not include new customers in this calculation, otherwise the fetched insights will not be accurate.\n",
    "\n",
    "The company would like to make this churn percentage as close to 0% as possible. If the customer churn percentage is higher, that means the company is not getting revenue from the customers and without the profit, they can not operate as successfully as possible. \n",
    "\n",
    "According to The American Customer Satisfaction Index, which measures the overall customer satisfaction by sector according to a formula, reported that only 72.2% of customers are satisfied with their current telecom provider [Source](https://www.theacsi.org/acsi-benchmarks/benchmarks-by-sector). It means 27.8% of customers are highly risked of leaving the company. However, it doesn't mean satisfied customers will not leave. They might leave but it is not very likely that they will leave. In 2017, Canada's two telecommunication company Telus and BCE (Bell), reported that it cost them 50 times more to get new customers than it would have cost to retain existing customers [Source](https://telecoms.com/opinion/churn-is-breaking-the-telecoms-market-heres-how-to-fix-it/).\n",
    "\n",
    "\n",
    "The dataset used in the project is taken from [Kaggle](https://www.kaggle.com/abhinav89/telecom-customer). The dataset contains over 100 features and 100,000 instances. It does not contain any information about the time frame of the data collected or any related information. The features contain almost all the features regarding telecom customers in categorical and continuous values. To help reduce the customer churn percentage, the companies use predictive models, so they can offer special perks to those customers who are more likely to leave. \n",
    "\n",
    "Following are the steps to develop a customer churn prediction model\n",
    "\n",
    "1.   Data Analysis\n",
    "2.   Data Preprocessing\n",
    "3.   Feature Selection\n",
    "4.   Model Selection and Training\n",
    "5.   Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_Mean</th>\n",
       "      <th>mou_Mean</th>\n",
       "      <th>totmrc_Mean</th>\n",
       "      <th>da_Mean</th>\n",
       "      <th>ovrmou_Mean</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>vceovr_Mean</th>\n",
       "      <th>datovr_Mean</th>\n",
       "      <th>roam_Mean</th>\n",
       "      <th>change_mou</th>\n",
       "      <th>...</th>\n",
       "      <th>forgntvl</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>kid0_2</th>\n",
       "      <th>kid3_5</th>\n",
       "      <th>kid6_10</th>\n",
       "      <th>kid11_15</th>\n",
       "      <th>kid16_17</th>\n",
       "      <th>creditcd</th>\n",
       "      <th>eqpdays</th>\n",
       "      <th>Customer_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.9975</td>\n",
       "      <td>219.25</td>\n",
       "      <td>22.500</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-157.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>361.0</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.4925</td>\n",
       "      <td>482.75</td>\n",
       "      <td>37.425</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>22.75</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.9900</td>\n",
       "      <td>10.25</td>\n",
       "      <td>16.990</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>1000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0000</td>\n",
       "      <td>7.50</td>\n",
       "      <td>38.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>1000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.2300</td>\n",
       "      <td>570.50</td>\n",
       "      <td>71.980</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_Mean  mou_Mean  totmrc_Mean  da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
       "0   23.9975    219.25       22.500   0.2475         0.00          0.0   \n",
       "1   57.4925    482.75       37.425   0.2475        22.75          9.1   \n",
       "2   16.9900     10.25       16.990   0.0000         0.00          0.0   \n",
       "3   38.0000      7.50       38.000   0.0000         0.00          0.0   \n",
       "4   55.2300    570.50       71.980   0.0000         0.00          0.0   \n",
       "\n",
       "   vceovr_Mean  datovr_Mean  roam_Mean  change_mou  ...  forgntvl  ethnic  \\\n",
       "0          0.0          0.0        0.0     -157.25  ...       0.0       N   \n",
       "1          9.1          0.0        0.0      532.25  ...       0.0       Z   \n",
       "2          0.0          0.0        0.0       -4.25  ...       0.0       N   \n",
       "3          0.0          0.0        0.0       -1.50  ...       0.0       U   \n",
       "4          0.0          0.0        0.0       38.50  ...       0.0       I   \n",
       "\n",
       "   kid0_2  kid3_5  kid6_10  kid11_15  kid16_17  creditcd  eqpdays  Customer_ID  \n",
       "0       U       U        U         U         U         Y    361.0      1000001  \n",
       "1       U       U        U         U         U         Y    240.0      1000002  \n",
       "2       U       Y        U         U         U         Y   1504.0      1000003  \n",
       "3       Y       U        U         U         U         Y   1812.0      1000004  \n",
       "4       U       U        U         U         U         Y    434.0      1000005  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# basic library import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to split the data into random smaller sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(\"Telecom_customer churn.csv\", 'r') as file:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "X_train, X_test = train_test_split(df, test_size = 0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code on this cell has been from tutorial 2 CSCI 4146 course\n",
    "def buildContinuousFeaturesReport(features, data_df):\n",
    "\tconHead = ['Count', 'Miss %', 'Card.', 'Min', '1st Qrt.',\n",
    "            'Mean', 'Median', '3rd Qrt.', 'Max', 'Std. Dev.']\n",
    "\n",
    "\tconOut_df = pd.DataFrame(index=features, columns=conHead)\n",
    "\tcolumns_df = data_df[features]\n",
    "\n",
    "\t#COUNT\n",
    "\tconOut_df[conHead[0]] = len(columns_df)\n",
    "\n",
    "\t#MISS % \n",
    "\tconOut_df[conHead[1]] = columns_df.isna().sum() / len(columns_df) * 100\n",
    "\n",
    "\t#CARDINALITY\n",
    "\tconOut_df[conHead[2]] = columns_df.nunique()\n",
    "\n",
    "\t#MINIMUM\n",
    "\tconOut_df[conHead[3]] = columns_df.min()\n",
    "\n",
    "\t#1ST QUARTILE\n",
    "\tconOut_df[conHead[4]] = columns_df.quantile(0.25)\n",
    "\n",
    "\t#MEAN\n",
    "\tconOut_df[conHead[5]] = columns_df.mean()\n",
    "\n",
    "\t#MEDIAN\n",
    "\tconOut_df[conHead[6]] = columns_df.median()\n",
    "\n",
    "\t#3rd QUARTILE\n",
    "\tconOut_df[conHead[7]] = columns_df.quantile(0.75)\n",
    "\n",
    "\t#MAX\n",
    "\tconOut_df[conHead[8]] = columns_df.max()\n",
    "\n",
    "\t#STANDARD DEVIATION\n",
    "\tconOut_df[conHead[9]] = columns_df.std()\n",
    "\n",
    "\treturn conOut_df\n",
    "\n",
    "def buildCategoricalFeaturesReport(features, data_df):\n",
    "\tcatHead = ['Count', 'Miss %', 'Card.', 'Mode', 'Mode Freq',\n",
    "            'Mode %', '2nd Mode', '2nd Mode Freq', '2nd Mode %']\n",
    "\n",
    "\tcolumns_df = data_df[features]\n",
    "\n",
    "\t#preparing a dictionary for storing data\n",
    "\tstats_dict = {k: ['']*len(features) for k in catHead}\n",
    "\n",
    "\t#CARDINALITY\n",
    "\tstats_dict['Card.'] = columns_df.nunique()\n",
    "\n",
    "\tmissing = columns_df.isna().sum() / len(columns_df) * 100\n",
    "\n",
    "\tfor col in columns_df:\n",
    "\t\tvalues = columns_df[col].value_counts()\n",
    "\t\tindex = features.index(col)\n",
    "\n",
    "    #COUNT\n",
    "\t\tstats_dict['Count'][index] = len(columns_df)\n",
    "\t\t\n",
    "\t\t#MISS %\n",
    "\t\tstats_dict['Miss %'][index] = missing[col]\n",
    "\n",
    "\t\t#MODES\n",
    "\t\tmode = values.index[0]\n",
    "\t\tmode2 = values.index[1] if len(values.index) > 1 else mode\n",
    "\t\tstats_dict['Mode'][index] = mode\n",
    "\t\tstats_dict['2nd Mode'][index] = mode2\n",
    "\n",
    "\t\t#MODE FREQ\n",
    "\t\tmodeCount = values.loc[mode]\n",
    "\t\tmodeCount2 = values.loc[mode2]\n",
    "\t\tstats_dict['Mode Freq'][index] = modeCount\n",
    "\t\tstats_dict['2nd Mode Freq'][index] = modeCount2\n",
    "\n",
    "\t\t#MODE %\n",
    "\t\tmiss = stats_dict['Miss %'][index]\n",
    "\n",
    "\t\tmodePer = (modeCount/(len(columns_df)*((100-miss)/100)))*100\n",
    "\t\tstats_dict['Mode %'][index] = round(modePer, 2)\n",
    "\n",
    "\t\tmodePer2 = (modeCount2/(len(columns_df)*((100-miss)/100)))*100\n",
    "\t\tstats_dict['2nd Mode %'][index] = round(modePer2, 2)\n",
    "\t\n",
    "\toutput_df = pd.DataFrame.from_dict(stats_dict)\n",
    "\treturn output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-3-25ca0815f14d>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-25ca0815f14d>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    with pd.option_context('display.max_rows', None, 'display.max_columns', None),\\\u001b[0m\n\u001b[1;37m                                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "# build the data quality reports(DQRs) for continuous and categorical features \n",
    "dqr_continuous_listings = buildContinuousFeaturesReport(X_train.select_dtypes('number').columns.to_list(), X_train)\n",
    "dqr_categorical_listings = buildCategoricalFeaturesReport(X_train.select_dtypes('object').columns.to_list(), X_train)\n",
    "\n",
    "#display the reports\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None),\\\n",
    "    pd.option_context('display.float_format', '{:.2f}'.format):\n",
    "        print(\"Data quality report for quantitative features\")\n",
    "        display(dqr_continuous_listings)\n",
    "\n",
    "        print(\"\\nData quality report for qualitative features\")\n",
    "        display(dqr_categorical_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Data Quality Reports, there are some features that contain numeric values but are qualitative by nature. Like, truck, rv, lor and others. So, let's move those features to the correct category and run the report again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move truck, rv, lor, adults, income, numbcars to categorical analysis\n",
    "\n",
    "lst_cat = ['truck', 'rv', 'lor', 'adults', 'income', 'numbcars']\n",
    "\n",
    "dqr_continuous_listings = dqr_continuous_listings.drop(lst_cat)\n",
    "\n",
    "lst_cat.extend(X_train.select_dtypes('object').columns.to_list())\n",
    "dqr_categorical_listings = buildCategoricalFeaturesReport(lst_cat, X_train)\n",
    "\n",
    "#display the reports\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None),\\ \n",
    "    pd.option_context('display.float_format', '{:.2f}'.format):\n",
    "        print(\"Data quality report for quantitative features\")\n",
    "        display(dqr_continuous_listings)\n",
    "\n",
    "        print(\"\\nData quality report for qualitative features\")\n",
    "        display(dqr_categorical_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DQR of quantitative features shows that most of the features for means or total (ends with '_Means' or starts with 'avg' or 'adj' or 'tot') have a higher number of outliers, i.e. difference between 3rd Qrtile and max value is too big. The box plot and histogram can help to gain some more information about these features, to make sound decisions for handling them. The missing values in features are not that high, so handling them is not a big task that requires a lot of analysis.\n",
    "\n",
    "Some features contain high values but from the problem domain knowledge, these values are not feasible. This might be because of a collection error or the wrong value. This needs to analyze further along with the feature (\"eqpdays\"). The \"eqpdays\" represents how since when (number of days) the customer has the current equipment, i.e. how long ago the customer got the equipment they are using. This feature contains negative values, which does not make sense unless it means that the new equipment is on the way (in the shipping) to the customer. Since the information is not provided, analysis is required before making any decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features with high number of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the boxplot and histogram for the given features from given dataframe\n",
    "def plot(df, features):\n",
    "    for i in features:    \n",
    "        df.boxplot(column=i)\n",
    "        plt.title('Boxplot of '+ i)\n",
    "        df.hist(column=i)\n",
    "        plt.title('Histogram of '+ i)\n",
    "        plt.show()\n",
    "\n",
    "lst_not_high_outliers = ['churn', 'months', 'uniqsubs', 'actvsubs', 'phones', \\\n",
    "                         'models', 'forgntvl', 'Customer_ID']\n",
    "\n",
    "lst_high_outliers = set(dqr_continuous_listings.index) - set(lst_not_high_outliers)\n",
    "\n",
    "plot(X_train, lst_high_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features with wrong high value analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniqsubs analysis\n",
    "print(\"Check values in uniqsubs\")\n",
    "plt.title(\"uniqsubs values > 10\")\n",
    "plt.xlabel(\"Number of unique subscriptions\")\n",
    "X_train[X_train['uniqsubs'] > 10]['uniqsubs'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actvsubs analysis\n",
    "print(\"Check values in actvsubs\")\n",
    "plt.title(\"actvsubs values > 5\")\n",
    "plt.xlabel(\"Number of actvsubs subscriptions\")\n",
    "X_train[X_train['actvsubs'] > 5]['actvsubs'].hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phones analysis\n",
    "print(\"Check values in phones\")\n",
    "plt.title(\"phones values > 10\")\n",
    "plt.xlabel(\"Number of phones issued\")\n",
    "X_train[X_train['phones'] > 10]['phones'].hist(bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models analysis\n",
    "print(\"Check values in models\")\n",
    "plt.title(\"models values > 5\")\n",
    "plt.xlabel(\"Number of models issued\")\n",
    "X_train[X_train['models'] > 5]['models'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features with wrong negative values analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eqpdays analysis\n",
    "print(\"Check values in eqpdays\")\n",
    "plt.title(\"eqpdays values < 5\")\n",
    "plt.xlabel(\"Number of days (age) of current equipment\")\n",
    "X_train[X_train['eqpdays'] < 5]['eqpdays'].hist()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"eqpdays\")\n",
    "plt.xlabel(\"Number of days (age) of current equipment\")\n",
    "X_train['eqpdays'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features with more than 10% missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_missing =  dqr_categorical_listings[(dqr_categorical_listings['Miss %'] > 10)].index.to_list()\n",
    "\n",
    "for f in high_missing:\n",
    "    print(\"Feature :\", f)\n",
    "    plt.title(f)\n",
    "    plt.xlabel(\"Values\")\n",
    "    plt.ylabel(\"% of customers\")\n",
    "    X_train[f].value_counts(normalize=True, dropna = False).plot(kind='bar')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features with smaller number of values analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_features = ['asl_flag', 'refurb_new', 'ownrent', 'dwlltype', 'infobase', \\\n",
    "              'kid0_2', 'kid3_5', 'kid6_10', 'kid11_15', 'kid16_17', \\\n",
    "              'creditcd', 'new_cell', 'prizm_social_one', 'hnd_webcap', \\\n",
    "              'marital', 'HHstatin']\n",
    "\n",
    "for f in lst_features:\n",
    "    print(\"Feature :\", f)\n",
    "    plt.title(f)\n",
    "    plt.xlabel(\"Values\")\n",
    "    plt.ylabel(\"% of customers\")\n",
    "    X_train[f].value_counts(normalize=True, dropna = False).plot(kind='bar')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features with uncommon values analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('dualband')\n",
    "plt.xlabel(\"Values\")\n",
    "plt.ylabel(\"% of customers\")\n",
    "X_train['dualband'].value_counts(normalize=True, dropna = False).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features with large values analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_features = ['crclscod', 'area', 'dwllsize', 'ethnic']\n",
    "\n",
    "for f in lst_features:\n",
    "    print(\"Feature :\", f)\n",
    "    plt.title(f)\n",
    "    plt.xlabel(\"Values\")\n",
    "    plt.ylabel(\"% of customers\")\n",
    "    X_train[f].value_counts(normalize=True, dropna = False).plot(kind='bar')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
